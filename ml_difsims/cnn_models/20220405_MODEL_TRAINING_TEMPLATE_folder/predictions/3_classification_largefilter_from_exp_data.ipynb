{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Predicting phases for experimental dataset\n",
    "# For the large filter dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "%matplotlib qt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os, glob\n",
    "import gc\n",
    "import tqdm\n",
    "import hyperspy.api as hs\n",
    "from tempfile import TemporaryFile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import examples of experimental data to process\n",
    "If only one file to predict, make it a list `data` of a single path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "['C:\\\\Users\\\\Sauron\\\\PycharmProjects\\\\ml_pyxem\\\\mini_2\\\\experimental_data\\\\npz_files\\\\20200209_163154_centre_rebin_correct_rb_radial_norm_cropK.npz',\n 'C:\\\\Users\\\\Sauron\\\\PycharmProjects\\\\ml_pyxem\\\\mini_2\\\\experimental_data\\\\npz_files\\\\roi_3_rebin_radial_norm_cropK.npz',\n 'C:\\\\Users\\\\Sauron\\\\PycharmProjects\\\\ml_pyxem\\\\mini_2\\\\experimental_data\\\\npz_files\\\\roi_4_rebin_radial_norm_cropK.npz']"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = r'C:\\Users\\Sauron\\PycharmProjects\\ml_pyxem\\mini_2'\n",
    "folder = r'experimental_data\\npz_files'\n",
    "\n",
    "file_extension = '*K.npz' # Select the q cropped file (rebinned)\n",
    "#file_extension = '*PX.npz' # Select the px cropped file (no rebin)\n",
    "\n",
    "path = os.path.join(root,folder,file_extension)\n",
    "paths = glob.glob(path)\n",
    "paths.sort()\n",
    "paths"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load the models to predict from\n",
    "Will search for the model in the same folder or one folder up."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'..\\\\20220405_CNN_large_filter_cnn_3nclasses_2epochs_64batchsize__train_22500n_0p9732ac__test_7500n_0.9691ac.h5'"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file_extension = '*.h5'\n",
    "\n",
    "# Select which model to use\n",
    "try:\n",
    "    model_path = glob.glob(model_file_extension, recursive=True)[0]\n",
    "except IndexError:\n",
    "    model_path = glob.glob(os.path.join('..', model_file_extension), recursive=True)[0]\n",
    "\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 142, 64)           448       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 71, 64)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 66, 64)            24640     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 33, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 33, 64)            0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 28, 64)            24640     \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 14, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 896)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               114816    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164,931\n",
      "Trainable params: 164,931\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m = tf.keras.models.load_model(model_path)\n",
    "m.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:10<00:00,  3.61s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/16129 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "41fc77f2f1544b27bc9c9865134a7734"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/500 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1264515748bc4b289b5f772dcf1279e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/728 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e6e6c3c705254bf483e0f7859a89f866"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "######### Run the predicting\n",
    "\n",
    "# Load model\n",
    "model_basename = os.path.basename(model_path).split('.')[0]\n",
    "model_dir = os.path.dirname(model_path)\n",
    "\n",
    "for i, fname in enumerate(tqdm.tqdm(paths)):\n",
    "    exp_name = os.path.basename(fname).split('.')[0]\n",
    "    exp_npzfile = np.load(fname)\n",
    "    exp_data = exp_npzfile['exp1d']\n",
    "    shape = (exp_data.shape[0] * exp_data.shape[1], exp_data.shape[2], 1)\n",
    "    exp_data_reshape = np.reshape(exp_data, shape)\n",
    "    exp_preds = m.predict(exp_data_reshape)\n",
    "    n_phases = exp_preds.shape[-1]\n",
    "    shape = (exp_data.shape[0], exp_data.shape[1], n_phases)\n",
    "    exp_pred_reshape = np.reshape(exp_preds, shape)\n",
    "    # Transpose so phase is the navigation axis\n",
    "    exp_pred_reshape = np.moveaxis(exp_pred_reshape, -1, 0)\n",
    "    s = hs.signals.Signal2D(exp_pred_reshape)\n",
    "\n",
    "    del exp_npzfile\n",
    "    del exp_data\n",
    "    del exp_data_reshape\n",
    "    del exp_preds\n",
    "    del exp_pred_reshape\n",
    "    gc.collect()\n",
    "\n",
    "    # Add phases in the metadata\n",
    "    metadata_path = glob.glob(os.path.join(model_dir, 'phase_names*.npy'))[0]\n",
    "    phases = np.load(metadata_path)\n",
    "    phases = [s for s in phases]\n",
    "    s.metadata.General.set_item(\"Phases\", phases)\n",
    "    s.metadata.General.set_item(\"Model trained\", model_basename)\n",
    "\n",
    "    ## Save results in 2 folders\n",
    "    # Save the stack with probabilites\n",
    "    file_name = f'probability_preditions_{exp_name}.hspy'\n",
    "    s.save(file_name, overwrite=True)\n",
    "\n",
    "    # Plot prob distribution maps\n",
    "    f = plt.figure(figsize= (5 * len(phases), 5))\n",
    "    hs.plot.plot_images(s, vmax=1, vmin=0, cmap='viridis', colorbar='single',\n",
    "                        label=phases, axes_decor='off', scalebar=[0],\n",
    "                        suptitle='Probabilty predictions', fig=f, tight_layout=True,)\n",
    "    plt.savefig(file_name.replace('hspy', 'png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Save the sparse categorical results [1 to n]\n",
    "    signal_cat = hs.signals.Signal2D(s.data.argmax(axis=0))\n",
    "    signal_cat.metadata.General.set_item(\"Phases\", phases)\n",
    "    signal_cat.metadata.General.set_item(\"Model trained\", model_basename)\n",
    "    file_name = f'sparse_categorical_{exp_name}.hspy'\n",
    "    signal_cat.save(file_name, overwrite=True)\n",
    "\n",
    "    # Plot categorical file\n",
    "    from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "    ax = plt.subplot()\n",
    "    im = ax.imshow(signal_cat.data, cmap='viridis')\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    cbar = plt.colorbar(im, cax=cax, ticks=np.arange(len(phases)))\n",
    "    cbar.ax.set_yticklabels(phases)\n",
    "    plt.title('Argmax value')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(file_name.replace('hspy', 'png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Save the one-hot encoded categorical results [0,1,...,0]\n",
    "    def cont_to_categorical(continous_ar):\n",
    "        b =  np.zeros_like(continous_ar)\n",
    "        b[np.argmax(continous_ar)] = 1\n",
    "        return b\n",
    "\n",
    "    signal_cat_expanded = s.T.map(cont_to_categorical, inplace=False,)\n",
    "    signal_cat_expanded.metadata.General.set_item(\"Phases\", phases)\n",
    "    signal_cat_expanded.metadata.General.set_item(\"Model trained\", model_basename)\n",
    "    file_name = f'onehot_categorical_{exp_name}.hspy'\n",
    "    signal_cat_expanded.save(file_name, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}